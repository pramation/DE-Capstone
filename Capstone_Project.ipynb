{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "  \n",
    "#### Project Summary\n",
    "In this project we will analyze the immigration into United States.We will try to answer following questions\n",
    "\n",
    "    * Travel pattern vis-a-vis seasons. This will help improve tourist management.\n",
    "    \n",
    "    * Find the busiest port of entries during the year. This will help with capacity planning at the airport.\n",
    "    \n",
    "    * Analyze relation between port of entry, final destination and demographics of various cities.\n",
    " \n",
    " We will use the following datasets for this project:\n",
    " \n",
    "    I94 immigration Dataset: This data is from US National Tourism and Trade Office. This file along with other information has entry-exit information of each foreign national coming into US. This information will be source of our fact table in our data model.This dataset has data dictionary which contains lookup values for i94cit &i94res, i94port, i94addr, i94mode and i94visa.\n",
    "    \n",
    "    U.S City Demographic Dataset: This data comes from OpenSoft. It has information about the population in a given city of a state eg: total population, average age of the population, etc.This will be the source of state dimension table data.\n",
    "    \n",
    "    Airport Codes Dataset: This dataset comes from DataHub. It has information related to airports eg. Airport code, location information, etc. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### i94 Immigration Dataset\n",
    "    Immigration dataset is the main dataset, has more than 3 million rows. This data will be the source of our fact table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "i94_sample_df=pd.read_csv(\"immigration_data_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port',\n",
       "       'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa',\n",
       "       'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd',\n",
       "       'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum',\n",
       "       'airline', 'admnum', 'fltno', 'visatype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_sample_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160428</td>\n",
       "      <td>DOH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>721257</td>\n",
       "      <td>1481650.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20552.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>20606.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>10072016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DL</td>\n",
       "      <td>7.368526e+08</td>\n",
       "      <td>910</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1072780</td>\n",
       "      <td>2197173.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>20556.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20635.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>10112016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CX</td>\n",
       "      <td>7.863122e+08</td>\n",
       "      <td>870</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>112205</td>\n",
       "      <td>232708.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20546.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>06302016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.547449e+10</td>\n",
       "      <td>00117</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2577162</td>\n",
       "      <td>5227851.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20575.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>07262016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LX</td>\n",
       "      <td>5.941342e+10</td>\n",
       "      <td>00008</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10930</td>\n",
       "      <td>13213.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>5.544979e+10</td>\n",
       "      <td>00109</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "5      721257  1481650.0  2016.0     4.0   577.0   577.0     ATL  20552.0   \n",
       "6     1072780  2197173.0  2016.0     4.0   245.0   245.0     SFR  20556.0   \n",
       "7      112205   232708.0  2016.0     4.0   113.0   135.0     NYC  20546.0   \n",
       "8     2577162  5227851.0  2016.0     4.0   131.0   131.0     CHI  20572.0   \n",
       "9       10930    13213.0  2016.0     4.0   116.0   116.0     LOS  20545.0   \n",
       "\n",
       "   i94mode i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup  \\\n",
       "0      1.0      HI  20573.0    61.0      2.0    1.0  20160422      NaN   NaN   \n",
       "1      1.0      TX  20568.0    26.0      2.0    1.0  20160423      MTR   NaN   \n",
       "2      1.0      FL  20571.0    76.0      2.0    1.0  20160407      NaN   NaN   \n",
       "3      1.0      CA  20581.0    25.0      2.0    1.0  20160428      DOH   NaN   \n",
       "4      3.0      NY  20553.0    19.0      2.0    1.0  20160406      NaN   NaN   \n",
       "5      1.0      GA  20606.0    51.0      2.0    1.0  20160408      NaN   NaN   \n",
       "6      1.0      CA  20635.0    48.0      2.0    1.0  20160412      NaN   NaN   \n",
       "7      1.0      NY  20554.0    33.0      2.0    1.0  20160402      NaN   NaN   \n",
       "8      1.0      IL  20575.0    39.0      2.0    1.0  20160428      NaN   NaN   \n",
       "9      1.0      CA  20553.0    35.0      2.0    1.0  20160401      NaN   NaN   \n",
       "\n",
       "  entdepa entdepd  entdepu matflag  biryear   dtaddto gender  insnum airline  \\\n",
       "0       G       O      NaN       M   1955.0  07202016      F     NaN      JL   \n",
       "1       G       R      NaN       M   1990.0  10222016      M     NaN     *GA   \n",
       "2       G       O      NaN       M   1940.0  07052016      M     NaN      LH   \n",
       "3       G       O      NaN       M   1991.0  10272016      M     NaN      QR   \n",
       "4       Z       K      NaN       M   1997.0  07042016      F     NaN     NaN   \n",
       "5       T       N      NaN       M   1965.0  10072016      M     NaN      DL   \n",
       "6       T       O      NaN       M   1968.0  10112016      F     NaN      CX   \n",
       "7       G       O      NaN       M   1983.0  06302016      F     NaN      BA   \n",
       "8       O       O      NaN       M   1977.0  07262016    NaN     NaN      LX   \n",
       "9       O       O      NaN       M   1981.0  06292016    NaN     NaN      AA   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  5.658267e+10  00782       WT  \n",
       "1  9.436200e+10  XBLNG       B2  \n",
       "2  5.578047e+10  00464       WT  \n",
       "3  9.478970e+10  00739       B2  \n",
       "4  4.232257e+10   LAND       WT  \n",
       "5  7.368526e+08    910       B2  \n",
       "6  7.863122e+08    870       B2  \n",
       "7  5.547449e+10  00117       WT  \n",
       "8  5.941342e+10  00008       WT  \n",
       "9  5.544979e+10  00109       WT  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns',30)\n",
    "i94_sample_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Lookup tables\n",
    "    Immigration dataset has codes as the values in several of its columns. To get actual value of these codes, we need lookup values. To get the names of the country for each of these country codes,\n",
    "    we can we can use these lookup table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94Addr_lookup_df=pd.read_csv(\"i94addr.csv\",sep='=')\n",
    "i94CitRes_lookup_df=pd.read_csv(\"i94citRes.csv\",sep='=')\n",
    "i94Prtl_lookup_df=pd.read_csv(\"i94prtl.csv\",sep=',')\n",
    "i94Mode_lookup_df=pd.read_csv(\"i94mode.csv\",sep='=')\n",
    "i94Visa_lookup_df=pd.read_csv(\"i94visa.csv\",sep='=')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CCODE', 'CNAME'], dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i94_addr_lookup_df.columns\n",
    "i94CitRes_lookup_df.columns\n",
    "#i94Prtl_lookup_df\n",
    "#i94Mode_lookup_df\n",
    "#i94Visa_lookup_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Airport Codes Dataset: \n",
    "    Contains data from International Air Transport Association (IATA).  Has data aout Airport Codes. This will be source for our Airport Dimention table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airports_df = pd.read_csv('airport-codes_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ident', 'type', 'name', 'elevation_ft', 'continent', 'iso_country',\n",
       "       'iso_region', 'municipality', 'gps_code', 'iata_code', 'local_code',\n",
       "       'coordinates'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### US Demographics Dataset: \n",
    "    Contains Data about the demographics of all US cities . This is the source for usDemographics table. This together with the immigration fact table will give interesting insigts to people arriving cities Vs city they choose to stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_city_demographics_df = pd.read_csv('us-cities-demographics.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "\n",
       "   Average Household Size State Code                Race  Count  \n",
       "0                    2.60         MD  Hispanic or Latino  25924  \n",
       "1                    2.39         MA               White  58723  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_city_demographics_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|     F|\n",
      "|  null|\n",
      "|     M|\n",
      "|     U|\n",
      "|     X|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mainDF_i94=spark.read.parquet(\"/home/workspace/sas_data\")\n",
    "mainDF_i94[['gender']].distinct().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "#df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Performing cleaning tasks here\n",
    "* Remove records where primary key values are null.\n",
    "* Convert date column to proper date \n",
    "* Convert lower case values to upper case\n",
    "* remove unneccessary columns\n",
    "* strip spaces from the values in lookup tables.\n",
    "* Remove records that has port of entry as non-US \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Exploring Airport Data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55075, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total of 55075 rows with 12 columns of which 247 rows have missing iso_country value.\n",
    "airports_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45886, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More than 50% of the values in  Continent & local_code columns  and 80% in iata_code are missing so we can ignore these columns.\n",
    "# Filter out rows with iso_country value is missing.\n",
    "\n",
    "airports_df[airports_df['iso_country'].isna()].shape\n",
    "airports_df[airports_df['iata_code'].isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since airport dataset does not have airport code, we will use combination municipality & country to map to the airport code i94prtl lookup table.We will ensure \n",
    "# We will ensure iso_country & municipality fields are not null.We will also convert it into uppercase to join with the lookup table.\n",
    "\n",
    "airports_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "balloonport          23\n",
       "closed             2966\n",
       "heliport          10927\n",
       "large_airport       610\n",
       "medium_airport     4007\n",
       "seaplane_base       792\n",
       "small_airport     29929\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are serveral airport type which are either closed or used for recreational purposes and not a potential international flights. we will filter out those.\n",
    "\n",
    "airports_df=airports_df[['ident', 'type', 'name', 'elevation_ft', 'continent', 'iso_country',\n",
    "       'iso_region', 'municipality', 'gps_code', 'local_code', 'coordinates']]\n",
    "\n",
    "airports_df=airports_df.dropna(subset=['iso_country','municipality'])\n",
    "airports_df.groupby('type')['type'].count()\n",
    "\n",
    "typenotin=['balloonport','closed','seaplane_base','heliport']\n",
    "airports_df_final=airports_df[~airports_df['type'].isin(typenotin)].copy()\n",
    "\n",
    "airports_df_final['municipality']=airports_df_final['municipality'].str.upper()\n",
    "\n",
    "\n",
    "airports_df_final.columns\n",
    "airports_df.groupby('type')['type'].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### US Demographics Dataset   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2891, 12)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This Dataset has a total 2891 records with 12 columns.\n",
    "\n",
    "us_city_demographics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "\n",
       "   Average Household Size State Code                Race  Count  \n",
       "0                    2.60         MD  Hispanic or Latino  25924  \n",
       "1                    2.39         MA               White  58723  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_city_demographics_df.head(2)\n",
    "#us_city_demographics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are no missing values for City,State_code & Race columns, This will form our Primary Key\n",
    "\n",
    "us_city_demographics_df[['City','State Code','Race']].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SILVER SPRING</td>\n",
       "      <td>MARYLAND</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUINCY</td>\n",
       "      <td>MASSACHUSETTS</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  SILVER SPRING       MARYLAND        33.8          40601.0   \n",
       "1         QUINCY  MASSACHUSETTS        41.0          44129.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "\n",
       "   Average Household Size State Code                Race  Count  \n",
       "0                    2.60         MD  Hispanic or Latino  25924  \n",
       "1                    2.39         MA               White  58723  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to convert City and State columns values to uppercase.\n",
    "\n",
    "us_city_demographics_df['City']=us_city_demographics_df['City'].str.upper()\n",
    "us_city_demographics_df['State']=us_city_demographics_df['State'].str.upper()\n",
    "us_city_demographics_df_final=us_city_demographics_df\n",
    "us_city_demographics_df_final.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Lookup Tables Dataset\n",
    "\n",
    "    This data is available as part of the data dictionary in the SAS file. Several columns in the immigration dataset has codes, \n",
    "    to get to the details of the codes, we need to get it from the lookup tables. These lookup values have been extracted from the data dictionary \n",
    "    file 'I94_SAS_Labels_Descriptions.SAS'.\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCODE</th>\n",
       "      <th>SNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SCODE    SNAME\n",
       "0    AL  ALABAMA\n",
       "1    AK   ALASKA"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i94Addr_lookup_df : - This has the code referenced by the column 'i94addr' which is basically a state code ex:AZ\n",
    "#                    - Has no missing value .\n",
    "#                    - i94addr is corresponds to scode(State Code) in this lookup and state name can be obtained.\n",
    "#                    - All the invalid codes are grouped with a value of 99\n",
    "#                    -*Need to trim the spaces.\n",
    "\n",
    "\n",
    "i94Addr_lookup_df['SCODE']=i94Addr_lookup_df['SCODE'].str.strip()\n",
    "i94Addr_lookup_df['SNAME']=i94Addr_lookup_df['SNAME'].str.strip()\n",
    "i94Addr_lookup_df_final=i94Addr_lookup_df\n",
    "i94Addr_lookup_df_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 289 entries, 0 to 288\n",
      "Data columns (total 2 columns):\n",
      "CCODE    289 non-null int64\n",
      "CNAME    289 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 4.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCODE</th>\n",
       "      <th>CNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CCODE                                              CNAME\n",
       "0    582  MEXICO Air Sea, and Not Reported (I-94, no lan...\n",
       "1    236                                        AFGHANISTAN"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i94CitRes_lookup_df : - This has the code referenced by the column 'i94cit & i94res' representing country of citizenship and country of residency.\n",
    "#                      - This column has a nemeric code for each of the country ex:242 for Bhutan \n",
    "#                      - This has about 289 values , there are few invalid country code. we will keep it for now.\n",
    "#                      - *Need to trim the leading and trailing spaces.\n",
    "\n",
    "i94CitRes_lookup_df.info()\n",
    "i94CitRes_lookup_df['CNAME']=i94CitRes_lookup_df['CNAME'].str.strip()\n",
    "i94CitRes_lookup_df_final=i94CitRes_lookup_df\n",
    "i94CitRes_lookup_df_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PECODE</th>\n",
       "      <th>PECITY</th>\n",
       "      <th>PESTATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PECODE     PECITY PESTATE\n",
       "0    ALC      ALCAN      AK\n",
       "1    ANC  ANCHORAGE      AK"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i94Prtl_lookup_df   : -This has a code referenced by the column 'i94port' reprsenting port of entry into US. \n",
    "#                      -This has the city Code. ex: CHI Chigago IL.\n",
    "#                      -This lookup table has three columns - code, city name, state name.\n",
    "#                      -Some of the values are invalid.\n",
    "#                      -*Need to trim the leading and trailing spaces.\n",
    "#                      -*We will filter out where state value is missing\n",
    "\n",
    "i94Prtl_lookup_df['PECODE']=i94Prtl_lookup_df['PECODE'].str.strip()\n",
    "i94Prtl_lookup_df['PECITY']=i94Prtl_lookup_df['PECITY'].str.strip()\n",
    "i94Prtl_lookup_df['PESTATE']=i94Prtl_lookup_df['PESTATE'].str.strip()\n",
    "\n",
    "i94Prtl_lookup_df_final=i94Prtl_lookup_df.dropna(subset=['PESTATE'])\n",
    "i94Prtl_lookup_df_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCODE</th>\n",
       "      <th>MNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>LAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NOT REPORTED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MCODE         MNAME\n",
       "0      1           AIR\n",
       "1      2           SEA\n",
       "2      3          LAND\n",
       "3      9  NOT REPORTED"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i94Mode_lookup_df   : -This is a code referenced by the 'i94mode' representing mode of entry into US ex: land, sea, air\n",
    "#                      -This column has a numerical value . ex: 1 for  Air.\n",
    "#                      -This lookup table has 2 columns - code and value \n",
    "#                      -*Need to trim the leading and trailing spaces.\n",
    "#                      -*Convert the value to uppercase.\n",
    "\n",
    "\n",
    "\n",
    "i94Mode_lookup_df['MNAME']=i94Mode_lookup_df['MNAME'].str.strip()\n",
    "i94Mode_lookup_df['MNAME']=i94Mode_lookup_df['MNAME'].str.upper()\n",
    "i94Mode_lookup_df_final=i94Mode_lookup_df\n",
    "i94Mode_lookup_df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VCODE</th>\n",
       "      <th>VNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PLEASURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>STUDENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VCODE     VNAME\n",
       "0      1  BUSINESS\n",
       "1      2  PLEASURE\n",
       "2      3   STUDENT"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i94Visa_lookup_df   : -This is a code referenced by the 'i94visa' representing the type of visa of traveller :ex: visit, travel\n",
    "#                      -This column has a numerical value . ex: 1 for  Business.\n",
    "#                      -This lookup table has 2 columns - code and value \n",
    "#                      -*Need to trim the leading and trailing spaces.\n",
    "#                      -*Convert the value to uppercase.\n",
    "\n",
    "i94Visa_lookup_df['VNAME']=i94Visa_lookup_df['VNAME'].str.strip()\n",
    "i94Visa_lookup_df['VNAME']=i94Visa_lookup_df['VNAME'].str.upper()\n",
    "i94Visa_lookup_df_final=i94Visa_lookup_df\n",
    "i94Visa_lookup_df_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "    There is one fact table , 3 dimention tables, 5 lookup tables.\n",
    "    \n",
    "US_DEMOGRPHY_D\n",
    "----------------\n",
    "Destination                     Cons    Relation\n",
    "========================================================\n",
    "City                             PK     I94prtl_L(port_city)\n",
    "State_code                       PK     I94prtl_L(port_state)\n",
    "Race                             PK\n",
    "Total_population    \n",
    "Male_population     \n",
    "Female_population   \n",
    "Median_age          \n",
    "Number_of_veterans \n",
    "Forgein_born        \n",
    "Avg_Household_size  \n",
    "State               \n",
    "\n",
    "Airport_D\n",
    "----------------\n",
    "Destination                  Cons    Relation\n",
    "========================================================\n",
    "id                            PK\n",
    "Airport_type        \n",
    "Airport_name       \n",
    "Elevation_feet      \n",
    "country             \n",
    "state                                 Trim country from region field\n",
    "municipality                          I94prtl_L(port_city)\n",
    "\n",
    "\n",
    "Immigration_F\n",
    "----------------\n",
    "Destination                         Cons       Relation\n",
    "==========================================================================\n",
    "cicid                                PK\n",
    "Citizenship_country_code             FK        I94cit_res_L(country_code)\n",
    "Residence_country_code               FK        I94cit_res_L(country_code)\n",
    "Port_of_entry                        FK        I94port_L(port_code)\n",
    "Arrival_date                         FK        Date_Time_D(Date_field)\n",
    "Departure_date                       FK        Date_Time_D(Date_field)\n",
    "Entry_mode                           FK        I94Mode_L(mode_code)\n",
    "Visa_type                            FK        I94visa_L(visa_code)\n",
    "Destination_state                    FK        I94addr_L(state_code)\n",
    "age                               \n",
    "occupation                       \n",
    "gender                           \n",
    "\n",
    "\n",
    "\n",
    "Date_Time_D\n",
    "------------------\n",
    "Date_field  PK\n",
    "year\n",
    "month\n",
    "day\n",
    "week\n",
    "weekday\n",
    "\n",
    "i94cit_res_L                                i94Mode_L\n",
    "------------------                     ------------------\n",
    "country_code PK                        mode_code       PK\n",
    "country_name                           mode_name\n",
    "\n",
    "\n",
    "i94visa_L                                i94cit_res_L\n",
    "-------------------                     ------------------          \n",
    "visa_code       PK                      country_code    PK\n",
    "visa_name                               country_name\n",
    " \n",
    "i94prtl_L                                 i94Addr_L\n",
    "-------------------                    ------------------                                   \n",
    "Port_code      PK                       state_code   PK\n",
    "Port_city                               state_name\n",
    "Port_state\n",
    "\n",
    "    \n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Extraction: \n",
    "      * Load all the data from files (csv and Parquet)\n",
    "#### Data Cleanup:\n",
    "   #### IMMIGRATION_F\n",
    "      *  Remove the rows where gender is null\n",
    "      *  Convert arrival and departure date into date format\n",
    "      *  remove any non-us i94port(port of entry)\n",
    "      *  insert data into immigration_f fact table\n",
    "      *  write to parquet file\n",
    "   #### us_demography_D\n",
    "      *  convert city and state fields to upper case\n",
    "      *  insert data into us_demography_d dimension table\n",
    "   #### Airports_D\n",
    "      *  remove rows with iso_country value is missing\n",
    "      *  remove where airport_type=('balloonport', 'closed', 'heliport', 'seaplane_base')\n",
    "      *  insert data into us_demography_d dimension table\n",
    "      *  separate country from the region in the iso_region column\n",
    "   #### i94Addr_L\n",
    "      *  trim the leading and trailing spaces for all the columns\n",
    "      *  convert the values into upper case\n",
    "      *  insert data into i94Addr_l dimension table\n",
    "   #### i94CitRes_L\n",
    "      *  trim the leading and trailing spaces for all the columns\n",
    "      *  convert the values into upper case\n",
    "      *  insert data into i94CitRes_l dimension table\n",
    "   #### i94Prtl_L\n",
    "      *  trim the leading and trailing spaces for all the columns\n",
    "      *  convert the values into upper case\n",
    "      *  remove records where state value is missing\n",
    "      *  insert data into i94Prtl_l dimension table\n",
    "   #### i94Mode_L\n",
    "      *  trim the leading and trailing spaces for all the columns\n",
    "      *  convert the values into upper case\n",
    "      *  insert data into i94Mode_l dimension table\n",
    "   #### i94Visa_L\n",
    "      *  trim the leading and trailing spaces for all the columns\n",
    "      *  convert the values into upper case\n",
    "      *  insert data into i94Visa_l dimension table\n",
    "   \n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Extract \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Spark reads the data from the source files into their respective DataFrames\n",
    "mainDF_i94=spark.read.parquet(\"/home/workspace/sas_data\")\n",
    "airports_df = spark.read.csv('airport-codes_csv.csv',inferSchema=True,header=True)\n",
    "us_city_demographics_df = spark.read.csv('us-cities-demographics.csv',sep=';',inferSchema=True,header=True)\n",
    "i94Addr_lookup_df=spark.read.csv(\"i94addr.csv\",sep='=',inferSchema=True,header=True)\n",
    "i94CitRes_lookup_df=spark.read.csv(\"i94citRes.csv\",sep='=',inferSchema=True,header=True)\n",
    "i94Prtl_lookup_df=spark.read.csv(\"i94prtl.csv\",sep=',',inferSchema=True,header=True)\n",
    "i94Mode_lookup_df=spark.read.csv(\"i94mode.csv\",sep='=',inferSchema=True,header=True)\n",
    "i94Visa_lookup_df=spark.read.csv(\"i94visa.csv\",sep='=',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Transform the data from airports DataFrame and apply various filters and create a view a dimension table AIRPORT_D\n",
    "\n",
    "airports_df['ident',\n",
    "'type',\n",
    "'name',\n",
    "'elevation_ft',\n",
    "'iso_country',\n",
    "'iso_region',\n",
    "'municipality'].createOrReplaceTempView('airports_v')\n",
    "\n",
    "airports_t=spark.sql(\"\"\"select ident as id,type as airport_type,name as airport_name, iso_country as country, substr(iso_region,instr(iso_region,'-')+1) as state, upper(municipality) as municipality \n",
    "             from airports_v\n",
    "             where (municipality is NOT NULL AND iso_country is NOT NULL AND type NOT IN ('heliport','small_airport','closed','seaplane_base','balloonport'))\n",
    "           \"\"\")\n",
    "\n",
    "airports_t.createOrReplaceTempView('airports_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Transform the data from US city demography DataFrame and apply various filters and create a view a dimension table US_DEMOGRAPHY_D\n",
    "\n",
    "us_city_demographics_df[['City',\n",
    "'Race',\n",
    "'State Code',\n",
    "'State',\n",
    "'Median Age',\n",
    "'Male Population',\n",
    "'Female Population',\n",
    "'Total Population',\n",
    "'Number of Veterans',\n",
    "'Foreign-born',\n",
    "'Average Household Size']].createOrReplaceTempView('us_demography_v')\n",
    "\n",
    "us_demography_t=spark.sql(\"\"\"SELECT UPPER(City) as city,\n",
    "                    UPPER(Race) as race,\n",
    "                    UPPER(`State Code`) as state_code,\n",
    "                    State as state,\n",
    "                    `Median Age` as median_age,\n",
    "                    `Male Population` as male_population,\n",
    "                    `Female Population` as female_population,\n",
    "                    `Total Population` as total_population,\n",
    "                    `Number of Veterans` as number_of_veterans,\n",
    "                    `Foreign-born` as number_of_foreign_born,\n",
    "                    `Average Household Size` as avg_household_size \n",
    "            FROM us_demography_v\n",
    "            WHERE city is NOT NULL and race is NOT NULL and `state code` is NOT NULL \"\"\")\n",
    "\n",
    "us_demography_t.createOrReplaceTempView('us_demography_d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Transform the data from various lookup DataFrame and apply clean up routines and create a corresponding view of the lookup tables.\n",
    "# Transform lookup or data dictionary tables for i94addr, i94citres, i94port, i94mode, i94visa columns of immigration table \n",
    "\n",
    "i94Addr_lookup_df.createOrReplaceTempView('i94addr_v')\n",
    "i94CitRes_lookup_df.createOrReplaceTempView('i94citres_v')\n",
    "i94Prtl_lookup_df.createOrReplaceTempView('i94port_v')\n",
    "i94Mode_lookup_df.createOrReplaceTempView('i94mode_v')\n",
    "i94Visa_lookup_df.createOrReplaceTempView('i94visa_v')\n",
    "\n",
    "i94addr_t=spark.sql(\"select trim(scode) state_code,trim(sname) as state_name from i94addr_v\")\n",
    "i94citres_t=spark.sql(\"select int(ccode) as country_code, UPPER(trim(cname)) as country_name from i94citres_v\")\n",
    "i94port_t=spark.sql(\"\"\"select trim(PECODE) as port_of_entry_code,trim(PECITY) as port_of_entry_city,trim(PESTATE) as port_of_entry_state\n",
    "                       from i94port_v \n",
    "                       \"\"\")\n",
    "i94mode_t=spark.sql(\"select trim(MCODE) as mode_code,trim(upper(MNAME)) as mode_name from i94mode_v\")\n",
    "i94visa_t=spark.sql(\"select int(vcode) as visa_code,trim(upper(vname)) as visa_name from i94visa_v\")\n",
    "i94addr_t.createOrReplaceTempView('i94addr_l')\n",
    "i94citres_t.createOrReplaceTempView('i94citres_l')\n",
    "i94port_t.createOrReplaceTempView('i94port_l')\n",
    "i94mode_t.createOrReplaceTempView('i94mode_l')\n",
    "i94visa_t.createOrReplaceTempView('i94visa_l')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Transform the data of immigration  DataFrame and apply clean up routines,filters  and create a corresponding view of the fact table.\n",
    "mainDF_i94[ 'cicid',\n",
    " 'i94yr',\n",
    " 'i94mon',\n",
    " 'i94cit',\n",
    " 'i94res',\n",
    " 'i94port',\n",
    " 'arrdate',\n",
    " 'dtadfile',\n",
    " 'i94mode',\n",
    " 'i94addr',\n",
    " 'depdate',\n",
    " 'dtaddto',\n",
    " 'i94bir',\n",
    " 'i94visa',\n",
    " 'occup',\n",
    " 'biryear',\n",
    " 'gender',\n",
    " 'visatype'].createOrReplaceTempView('immigration_v')\n",
    "\n",
    "\n",
    "immigration_t=spark.sql(\"\"\"select int(cicid) as cicid ,int(i94cit) as Citizenship_country_code,int(i94res) as Residence_country_code,i94port as Port_of_entry,i94mode as Entry_mode ,\n",
    " i94addr final_dest_state,to_date(dtadfile,'yyyyMMdd') as arrival_date,to_date(dtaddto,'yyyyMMdd') as departure_date,\n",
    " int(i94bir) as age, int(i94visa) Visa_type, occup as occupation, int(biryear) birth_year, gender, visatype admission_type\n",
    " from immigration_v\n",
    " where gender is NOT NULL\n",
    "       and date_format(to_date(dtadfile,'yyyyMMdd'),'YYYY') !='2013'\n",
    "       and i94port IN (select port_of_entry_code from i94port_l where length(port_of_entry_state)=2 )\"\"\")\n",
    "\n",
    "immigration_t.createOrReplaceTempView('immigration_f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a Date_Time_D dimention table, source as arrival and departure date , apply computational function to extract various aspects of date .\n",
    "#Create a Date_time_d tables with the values of the arrival and departure date\n",
    "date_time_df=spark.sql(\"\"\"select distinct arrival_date arr_dep_date from immigration_f\n",
    "                     UNION\n",
    "                     select distinct departure_date arr_dep_date from immigration_f\"\"\")\n",
    "date_time_df.createOrReplaceTempView('time_temp_v')\n",
    "\n",
    "date_time_t=spark.sql(\"\"\"select arr_dep_date,year(arr_dep_date) year,month(arr_dep_date) month,day(arr_dep_date) day,\n",
    "              CASE dayofweek(arr_dep_date) \n",
    "              WHEN 0 THEN 'SUN' \n",
    "              WHEN 1 THEN 'MON'\n",
    "              WHEN 2 THEN 'TUE'\n",
    "              WHEN 3 THEN 'WED'\n",
    "              WHEN 4 THEN 'THU'\n",
    "              WHEN 5 THEN 'FRI'\n",
    "              WHEN 6 THEN 'SAT'\n",
    "              END weekday,weekofyear(arr_dep_date) week from time_temp_v\"\"\")\n",
    "\n",
    "date_time_t.createOrReplaceTempView('time_d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write  all the data  into its repective data models in the form of parquet files.\n",
    "immigration_t.write.parquet(\"data_out/immigration_f.parquet\",mode='overwrite')\n",
    "airports_t.write.parquet(\"data_out/airports_d.parquet\",mode='overwrite')\n",
    "us_demography_t.write.parquet(\"data_out/us_demography_d.parquet\",mode='overwrite')\n",
    "date_time_t.write.parquet(\"data_out/date_time_d.parquet\",mode='overwrite')\n",
    "i94addr_t.write.parquet(\"data_out/i94addr_l.parquet\",mode='overwrite')\n",
    "i94citres_t.write.parquet(\"data_out/i94citres_l.parquet\",mode='overwrite')\n",
    "i94port_t.write.parquet(\"data_out/i94port_l.parquet\",mode='overwrite')\n",
    "i94mode_t.write.parquet(\"data_out/i94mode_l.parquet\",mode='overwrite')\n",
    "i94visa_t.write.parquet(\"data_out/i94visa_l.parquet\",mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Value Check.....................Pass\n",
      "Arrival date check ..................Pass\n",
      "Distinct primary key values check ...Pass\n",
      "===============================================\n",
      "      All Data Quality Checks  :     PASSED    \n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "\n",
    "def data_quality_check():\n",
    "    \n",
    "        immigration_q=spark.read.parquet(\"data_out/immigration_f.parquet\")\n",
    "        airports_q=spark.read.parquet(\"data_out/airports_d.parquet\")\n",
    "        us_demography_q=spark.read.parquet(\"data_out/us_demography_d.parquet\")\n",
    "        date_time_q=spark.read.parquet(\"data_out/date_time_d.parquet\")\n",
    "        i94addr_q=spark.read.parquet(\"data_out/i94addr_l.parquet\")\n",
    "        i94citres_q=spark.read.parquet(\"data_out/i94citres_l.parquet\")\n",
    "        i94port_q=spark.read.parquet(\"data_out/i94port_l.parquet\")\n",
    "        i94mode_q=spark.read.parquet(\"data_out/i94mode_l.parquet\")\n",
    "        i94visa_q=spark.read.parquet(\"data_out/i94visa_l.parquet\")\n",
    "\n",
    "        #Check if there are null values \n",
    "        v_immi_null=immigration_q.filter(immigration_q.gender.isNull()).count()\n",
    "        v_airport_null=airports_q.filter(airports_q['airport_type']=='closed').count()\n",
    "        v_demography_null=us_demography_q.filter(us_demography_q.city.isNull()).count()\n",
    "\n",
    "        if v_immi_null==0 and v_airport_null==0 and v_demography_null==0:\n",
    "            v_all_null_check=0\n",
    "            print('Null Value Check.....................Pass')\n",
    "        else:\n",
    "            v_all_null_check=1\n",
    "            print('Null Value Check.....................Fail')\n",
    "\n",
    "        # Check if all dates from immigration arrival date in time_d table\n",
    "        v_immi_arrival_date = spark.sql(\"\"\"select distinct arrival_date from immigration_f\n",
    "                     MINUS\n",
    "                     select arr_dep_date from time_d\"\"\").count()\n",
    "        if v_immi_arrival_date==0:\n",
    "            print(\"Arrival date check ..................Pass\")\n",
    "        else:\n",
    "            print(\"Arrival date check ..................Fail\")\n",
    "\n",
    "        # Check for primary key values are distinct\n",
    "        v_imm_pk=spark.sql(\"\"\"select A-B FROM (select count(cicid) A,count(distinct cicid) B  from immigration_f )\"\"\").collect()[0][0]\n",
    "        v_airport_pk=spark.sql(\"\"\"select A-B FROM (select count(id) A,count(distinct id) B  from airports_d )\"\"\").collect()[0][0]\n",
    "        v_dem_pk=spark.sql(\"\"\"select A-B FROM (select count(city,race,state_code) A,count(distinct city,race,state_code) B  from us_demography_d) \"\"\").collect()[0][0]\n",
    "        v_time_pk=spark.sql( \"\"\"select A-B FROM (select count(arr_dep_date) A, count(distinct arr_dep_date) B from time_d)\"\"\").collect()[0][0]\n",
    "        v_i94cit_pk=spark.sql( \"\"\"select A-B FROM (select count(country_code) A, count(distinct country_code) B from i94citres_l)\"\"\").collect()[0][0]\n",
    "        v_i94mode_pk=spark.sql( \"\"\"select A-B FROM (select count(mode_code) A, count(distinct mode_code) B from i94Mode_L)\"\"\").collect()[0][0]\n",
    "        v_i94visa_pk=spark.sql( \"\"\"select A-B FROM (select count(visa_code) A, count(distinct visa_code) B from i94visa_L) \"\"\").collect()[0][0]\n",
    "        v_i94port_pk=spark.sql( \"\"\"select A-B FROM (select count( port_of_entry_code) A, count(distinct  port_of_entry_code) B from i94port_l) \"\"\").collect()[0][0]\n",
    "        i94addr_pk=spark.sql( \"\"\"select A-B FROM (select count(state_code) A, count(distinct state_code) B from i94Addr_L) \"\"\").collect()[0][0]\n",
    "\n",
    "        if (v_imm_pk==0 and v_airport_pk==0 and v_dem_pk==0 and v_time_pk==0 and v_i94cit_pk==0 and v_i94mode_pk==0 and v_i94visa_pk==0 and v_i94port_pk==0 and i94addr_pk==0) :\n",
    "            v_all_pk_check=0\n",
    "            print(\"Distinct primary key values check ...Pass\")\n",
    "        else:\n",
    "            v_all_pk_check=1\n",
    "            print(\"Distinct primary key values check ...Fail\")\n",
    "        \n",
    "        if (v_all_pk_check==0 and v_immi_arrival_date==0 and v_all_null_check==0):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "                \n",
    "data_check=data_quality_check()\n",
    "\n",
    "if data_check:\n",
    "    print(\"===============================================\")\n",
    "    print(\"      All Data Quality Checks  :     PASSED    \")\n",
    "    print(\"===============================================\")\n",
    "else:\n",
    "    print(\"===============================================\")\n",
    "    print(\"      All Data Quality Checks  :     FAILED    \")\n",
    "    print(\"===============================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file.\n",
    "Please refer to the file \"DataDictionary_Fig.png\" for a pictorial representation of the DataDictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "\n",
    "* The tool used for data processing is Spark(pyspark) as the main dataset which is the immigration dataset is about 2.5 million records and spark is a good tool to process large data.\n",
    "\n",
    "* This tool/program can handle larger data without making much changes. I have used spark to process smaller datasets just to be consistent.\n",
    "\n",
    "* The immigration data which happens to be our main fact table is posted monthly to trade.gov, we should run this process monthly.This can be scheduled via cron utility.\n",
    "\n",
    "Different Scenario:\n",
    "   \n",
    "   * If the data is increated by 100x -  The source data files will be stored in aws s3 bucktes. then we can use Redshift as the target database. This is the AWS datawarehouse database and will enable a low latency inserts and fast querying option.The current data processing (pyspark program) will be able to handle 100x data. We will run this program on Spark frame work on AWS EMR cluster.\n",
    "   \n",
    "   * The data populates a dashboard that must be updated on a daily basis by 7am every day. We can use Airflow to execute this data pipeline. This pipeline, will first Extract the data from aws s3 buckets, Transforms the data and Loads the data into aws redshift database. Pipeline also performs data quality checks . Pipeline will also pre-aggregates the data into OLAP cubes and stores it into Amazon RDS database and sends email to relavant teams.\n",
    "\n",
    "   *  The database needed to be accessed by 100+ people .  Once the data is ready in the Amazon redshift database(DWH) to be consumed, this DWH data is pre-aggregated into OLAP cubes and are stored in Amazon RDS database which then is consumed by the BI Apps visualization dashboards. Amazon RDS can easily be accessed by 100+ simultaneous users and can be scaled up even further.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Sample output from each of the saved output tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_f=spark.read.parquet(\"data_out/immigration_f.parquet\")\n",
    "airports_d=spark.read.parquet(\"data_out/airports_d.parquet\")\n",
    "us_demography_d=spark.read.parquet(\"data_out/us_demography_d.parquet\")\n",
    "date_time_d=spark.read.parquet(\"data_out/date_time_d.parquet\")\n",
    "i94addr_l=spark.read.parquet(\"data_out/i94addr_l.parquet\")\n",
    "i94citres_l=spark.read.parquet(\"data_out/i94citres_l.parquet\")\n",
    "i94port_l=spark.read.parquet(\"data_out/i94port_l.parquet\")\n",
    "i94mode_l=spark.read.parquet(\"data_out/i94mode_l.parquet\")\n",
    "i94visa_l=spark.read.parquet(\"data_out/i94visa_l.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------+----------------------+-------------+----------+----------------+------------+--------------+---+---------+----------+----------+------+--------------+\n",
      "|  cicid|Citizenship_country_code|Residence_country_code|Port_of_entry|Entry_mode|final_dest_state|arrival_date|departure_date|age|Visa_type|occupation|birth_year|gender|admission_type|\n",
      "+-------+------------------------+----------------------+-------------+----------+----------------+------------+--------------+---+---------+----------+----------+------+--------------+\n",
      "|5748517|                     245|                   438|          LOS|       1.0|              CA|  2016-04-30|          null| 40|        1|      null|      1976|     F|            B1|\n",
      "|5748518|                     245|                   438|          LOS|       1.0|              NV|  2016-04-30|          null| 32|        1|      null|      1984|     F|            B1|\n",
      "+-------+------------------------+----------------------+-------------+----------+----------------+------------+--------------+---+---------+----------+----------+------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Immigration Fact table\n",
    "\n",
    "immigration_f.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+--------------------+-------+-----+------------+\n",
      "|  id|  airport_type|        airport_name|country|state|municipality|\n",
      "+----+--------------+--------------------+-------+-----+------------+\n",
      "| 5A8|medium_airport|Aleknagik / New A...|     US|   AK|   ALEKNAGIK|\n",
      "|AGGH|medium_airport|Honiara Internati...|     SB|   CT|     HONIARA|\n",
      "+----+--------------+--------------------+-------+-----+------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-------------+------------------+----------+-------------+----------+---------------+-----------------+----------------+------------------+----------------------+------------------+\n",
      "|         city|              race|state_code|        state|median_age|male_population|female_population|total_population|number_of_veterans|number_of_foreign_born|avg_household_size|\n",
      "+-------------+------------------+----------+-------------+----------+---------------+-----------------+----------------+------------------+----------------------+------------------+\n",
      "|SILVER SPRING|HISPANIC OR LATINO|        MD|     Maryland|      33.8|          40601|            41862|           82463|              1562|                 30908|               2.6|\n",
      "|       QUINCY|             WHITE|        MA|Massachusetts|      41.0|          44129|            49500|           93629|              4147|                 32935|              2.39|\n",
      "+-------------+------------------+----------+-------------+----------+---------------+-----------------+----------------+------------------+----------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+------------+----+-----+---+-------+----+\n",
      "|arr_dep_date|year|month|day|weekday|week|\n",
      "+------------+----+-----+---+-------+----+\n",
      "|  2016-05-13|2016|    5| 13|    SAT|  19|\n",
      "|  2016-05-31|2016|    5| 31|    WED|  22|\n",
      "+------------+----+-----+---+-------+----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+----------+\n",
      "|state_code|state_name|\n",
      "+----------+----------+\n",
      "|        AL|   ALABAMA|\n",
      "|        AK|    ALASKA|\n",
      "+----------+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+------------+--------------------+\n",
      "|country_code|        country_name|\n",
      "+------------+--------------------+\n",
      "|         582|MEXICO AIR SEA, A...|\n",
      "|         236|         AFGHANISTAN|\n",
      "+------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+------------------+------------------+-------------------+\n",
      "|port_of_entry_code|port_of_entry_city|port_of_entry_state|\n",
      "+------------------+------------------+-------------------+\n",
      "|               ALC|             ALCAN|                 AK|\n",
      "|               ANC|         ANCHORAGE|                 AK|\n",
      "+------------------+------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---------+---------+\n",
      "|mode_code|mode_name|\n",
      "+---------+---------+\n",
      "|        1|      AIR|\n",
      "|        2|      SEA|\n",
      "+---------+---------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---------+---------+\n",
      "|visa_code|visa_name|\n",
      "+---------+---------+\n",
      "|        1| BUSINESS|\n",
      "|        2| PLEASURE|\n",
      "+---------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports_d.show(2)\n",
    "us_demography_d.show(2)\n",
    "date_time_d.show(2)\n",
    "i94addr_l.show(2)\n",
    "i94citres_l.show(2)\n",
    "i94port_l.show(2)\n",
    "i94mode_l.show(2)\n",
    "i94visa_l.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
